{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04ca82e",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "To get started with Jupyter Notebook, follow these steps â†’\n",
    "\n",
    "1. Open your browser and search for \"Anaconda Navigator download for Windows\". Click on the first link, which will take you to the Anaconda website. Download and install the software.\n",
    "2. Once installed, open Anaconda Navigator. You'll see various software options like PyCharm and Jupyter Lab. Click on \"Install\" or \"Launch\" for Jupyter Notebook.\n",
    "3. Launching Jupyter Notebook will open a localhost webpage. Localhost means it creates a local server on your system, allowing you to view and manage your files.\n",
    "4. To create a new notebook, click \"New\" and select the desired kernel (in this case, Python). Your new notebook will have an. ipynb extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa348048",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "\n",
    "### Module 1 - GenerativeAI Fundamentals\n",
    "\n",
    "1. Introduction to AI and its Evolution\n",
    "2. Machine Learning vs Deep Learning vs GenerativeAI\n",
    "3. What is GenerativeAI and Its Real-World Applications\n",
    "4. NLP Fundamentals and How to Build a Text Pre-processing Pipeline\n",
    "5. Text Normalization and Tokenization\n",
    "6. Embedding and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb4d704d",
   "metadata": {},
   "source": [
    "## 1. Introduction to AI and Its Evolution\n",
    "\n",
    "<img src='g1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea139de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8017b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "1943 - A logical calculus of the ideas immanent in neurons activity - foundation of neural network\n",
    "\n",
    "1950 - turing test\n",
    "\n",
    "1956 - Artificial Intelligence - John McCarthy\n",
    "\n",
    "\n",
    "1965 - NLP\n",
    "\n",
    "1997 - IBM Deep blue defeats world champion\n",
    "\n",
    "2004 - self-driving cars\n",
    "\n",
    "2006 - deep learning - Geoffery Hinton\n",
    "\n",
    "2007 - Apple - voice recognition (siri added in 2011)\n",
    "\n",
    "2012 - AlexNet - deep CNN - computer vision\n",
    "\n",
    "2014 - Google Deep mind - AlphaGo defeats a human through reinforcement learning\n",
    "\n",
    "2017 - AlphaGo zero - just by self-play it defeats its predecessor without any human data.\n",
    "\n",
    "2020 - GPT-3\n",
    "\n",
    "2021 - Google - MUM (Multitask Unified Model)\n",
    "\n",
    "2022 - DALL-E 2 and stable diffusion bring GenerativeAI\n",
    "\n",
    "2023 - DeepMind - AlphaFold - accurately predicts the structure of all know proteins.\n",
    "\n",
    "2024 - LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeac929",
   "metadata": {},
   "source": [
    "## 2. Machine Learning vs Deep Learning vs GenerativeAI\n",
    "\n",
    "<img src='g2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2efab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3033b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cdda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79a0e03",
   "metadata": {},
   "source": [
    "## 3. What is GenerativeAI and Its Real-World Applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca60d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83838288",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ed222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ccd2c05",
   "metadata": {},
   "source": [
    "### Coding\n",
    "\n",
    "<img src='gif1.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8eced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b724d4",
   "metadata": {},
   "source": [
    "### Images and Videos\n",
    "\n",
    "<img src='gif2.gif' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8e82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47001fe",
   "metadata": {},
   "source": [
    "### Audio\n",
    "\n",
    "<img src='gif3.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560b858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae505d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b67583c9",
   "metadata": {},
   "source": [
    "## 4. NLP Fundamentals and How to Build a Text Pre-processing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84540303",
   "metadata": {},
   "source": [
    "<img src='n4.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a28d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e715b1ec",
   "metadata": {},
   "source": [
    "### Text processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ca506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864244b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d32810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw text\n",
    "\n",
    "\"<SUBJECT LINE> Employees details. \\\n",
    "<END><BODY TEXT>Attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove encodings\n",
    "\n",
    "\"Employees details. Attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower casing\n",
    "\n",
    "\"employees details. attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits to words\n",
    "\n",
    "\"employees details. attached are two files first, one is pairoll second is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters - @!#$%^\n",
    "\n",
    "\"employees details attached are two files first one is pairoll second is healtcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd23adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling corrections\n",
    "\n",
    "\"employees details attached are two files first one is payroll second is healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "\n",
    "\"employees details attached two files first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "\n",
    "\"employe detail attached two file first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization - ran->run, jumped->jump\n",
    "\n",
    "\"employe detail attach two file first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b161ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now the text is ready to feed into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20755b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54765a4e",
   "metadata": {},
   "source": [
    "## 5. Text Normalization and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29c274",
   "metadata": {},
   "source": [
    "Tokenization Example - https://platform.openai.com/tokenizer\n",
    "\n",
    "<img src='v42.png' />\n",
    "\n",
    "<img src='v43.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6553a",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "1. Word Tokenization\n",
    "2. Sentence Tokenization\n",
    "3. Regular Expression Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25801b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'this is a single sentence.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(tokens) # ['this', 'is', 'a', 'single', 'sentence', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9f8cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'single', 'sentence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation = [word.lower() for word in tokens if word.isalpha()]\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d421090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is the first sentence.', 'this is the second sentence.', 'this is the document.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57ce1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'sentence', '.'], ['this', 'is', 'the', 'second', 'sentence', '.'], ['this', 'is', 'the', 'document', '.']]\n"
     ]
    }
   ],
   "source": [
    "print([word_tokenize(sentence) for sentence in sent_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c195f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "print(stop_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c73f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'sentence', '.', 'second', 'sentence', '.', 'document', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "tokens = [token for token in word_tokenize(text) if token not in stop_words]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c01bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f34b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c48774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed130e01",
   "metadata": {},
   "source": [
    "## 6. Embedding and Word2Vec\n",
    "\n",
    "Dataset - https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d65d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2df71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path):\n",
    "    file = open(path, 'r', encoding='utf8')\n",
    "    model = {}\n",
    "    \n",
    "    for l in file:\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        value = np.array([float(val) for val in line[1:]])\n",
    "        model[word] = value\n",
    "    \n",
    "    return model\n",
    "\n",
    "glove = loadGlove('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50a49c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python']   # vector embedding for the word Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "700b9c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92803 ,  0.29096 ,  0.67837 ,  1.0444  , -0.72551 ,  2.1995  ,\n",
       "        0.88767 , -0.94782 ,  0.67426 ,  0.24908 ,  0.95722 ,  0.18122 ,\n",
       "        0.064263,  0.64323 , -1.6301  ,  0.94972 , -0.7367  ,  0.17345 ,\n",
       "        0.67638 ,  0.10026 , -0.033782, -0.76971 ,  0.40519 , -0.099516,\n",
       "        0.79654 ,  0.1103  , -0.076053, -0.090434,  0.015021, -1.137   ,\n",
       "        1.6803  , -0.34424 ,  0.77538 , -1.8718  , -0.17148 ,  0.31956 ,\n",
       "        0.093062,  0.004996,  0.25716 ,  0.52207 , -0.52548 , -0.93144 ,\n",
       "       -1.0553  ,  1.4401  ,  0.30807 , -0.84872 ,  1.9986  ,  0.10788 ,\n",
       "       -0.23633 , -0.17978 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['neural']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0129d31",
   "metadata": {},
   "source": [
    "### How the system know that these words are similar?\n",
    "\n",
    "\n",
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf288386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "178263a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92180053]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['dog'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f968f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19825255]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['piano'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76946819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7839043]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['king'].reshape(1,-1), glove['queen'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f09d1",
   "metadata": {},
   "source": [
    "## Words in 2D Embedding Space\n",
    "\n",
    "<img src='v44.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49de85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a24a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21716de",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "Neurons to GenerativeAI - https://god-level-python.notion.site/Neurons-to-GenerativeAI-Live-Bootcamp-a59ec2f641084c488179271fc077f0c4?pvs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef7ae46",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Research Paper\n",
    "- Attention is All You Need: https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e128b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

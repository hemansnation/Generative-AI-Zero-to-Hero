{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04ca82e",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "To get started with Jupyter Notebook, follow these steps â†’\n",
    "\n",
    "1. Open your browser and search for \"Anaconda Navigator download for Windows\". Click on the first link, which will take you to the Anaconda website. Download and install the software.\n",
    "2. Once installed, open Anaconda Navigator. You'll see various software options like PyCharm and Jupyter Lab. Click on \"Install\" or \"Launch\" for Jupyter Notebook.\n",
    "3. Launching Jupyter Notebook will open a localhost webpage. Localhost means it creates a local server on your system, allowing you to view and manage your files.\n",
    "4. To create a new notebook, click \"New\" and select the desired kernel (in this case, Python). Your new notebook will have an. ipynb extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa348048",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "\n",
    "### Module 1 - GenerativeAI Fundamentals\n",
    "\n",
    "1. Introduction to AI and its Evolution\n",
    "2. Machine Learning vs Deep Learning vs GenerativeAI\n",
    "3. What is GenerativeAI and Its Real-World Applications\n",
    "4. NLP Fundamentals and How to Build a Text Pre-processing Pipeline\n",
    "5. Text Normalization and Tokenization\n",
    "6. Embedding and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb4d704d",
   "metadata": {},
   "source": [
    "## 1. Introduction to AI and Its Evolution\n",
    "\n",
    "<img src='g1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3454627",
   "metadata": {},
   "source": [
    "https://newsletter.himanshuramchandani.co/p/nlp-in-a-nutshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69cf7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello AI\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8017b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicating human intelligence\n",
    "\n",
    "\n",
    "\n",
    "1943 - A logical calculus of the ideas immanent in neurons activity - foundation of neural network\n",
    "\n",
    "1950 - turing test\n",
    "\n",
    "1956 - Artificial Intelligence - John McCarthy\n",
    "\n",
    "1965 - NLP\n",
    "\n",
    "1997 - IBM Deep blue defeats world champion\n",
    "\n",
    "2004 - self-driving cars\n",
    "\n",
    "2006 - deep learning - Geoffery Hinton\n",
    "\n",
    "2007 - Apple - voice recognition (siri added in 2011)\n",
    "\n",
    "2012 - AlexNet - deep CNN - computer vision\n",
    "\n",
    "2014 - Google Deep mind - AlphaGo defeats a human through reinforcement learning\n",
    "\n",
    "2017 - AlphaGo zero - just by self-play it defeats its predecessor without any human data.\n",
    "\n",
    "2020 - GPT-3\n",
    "\n",
    "2021 - Google - MUM (Multitask Unified Model)\n",
    "\n",
    "2022 - DALL-E 2 and stable diffusion bring GenerativeAI\n",
    "\n",
    "2023 - DeepMind - AlphaFold - accurately predicts the structure of all know proteins.\n",
    "\n",
    "2024 - LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f6621",
   "metadata": {},
   "source": [
    "## 2. Machine Learning vs Deep Learning vs GenerativeAI\n",
    "\n",
    "<img src='g2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine Learning\n",
    "- feature engineering\n",
    "- structured data - tabular data, relational databse\n",
    "- domain knowledge for designing features\n",
    "- can be trained on small data\n",
    "- CPUs\n",
    "- understand the decision (not black box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3033b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep Learning\n",
    "- no need feature engineering\n",
    "- unstructred data - images, audio, video, text\n",
    "- minimum domain knowledge for manual feature engineering\n",
    "- need large amount of data to perform well\n",
    "- GPUs and TPUs\n",
    "- it considered as black box - it is harder to explain how it comeup with the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerativeAI\n",
    "\n",
    "Statistical modeling\n",
    "- generative modeling - generating numbers(probabilities)\n",
    "- GPUs and TPUs\n",
    "- need large and large amount of data (GPT3 - 500 Billion words/tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5e679",
   "metadata": {},
   "source": [
    "## 3. What is GenerativeAI and Its Real-World Applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca60d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ee7f935",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "text generation\n",
    "- ChatGPT\n",
    "- Gemini\n",
    "- Perplexity\n",
    "\n",
    "text creation\n",
    "- copy.ai\n",
    "\n",
    "translation\n",
    "- google translate\n",
    "- deepL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb176969",
   "metadata": {},
   "source": [
    "### Coding\n",
    "\n",
    "<img src='gif1.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "- amazon codewhisperer\n",
    "- github copilot\n",
    "\n",
    "code documenation\n",
    "- OpenAI codex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20731d88",
   "metadata": {},
   "source": [
    "### Images and Videos\n",
    "\n",
    "<img src='gif2.gif' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image ai art\n",
    "- DALL-E 2\n",
    "- midhourney (join their discord for testing)\n",
    "\n",
    "- canva\n",
    "\n",
    "video generation\n",
    "- deepfake\n",
    "- ai video editing - RunwayML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f65cf0",
   "metadata": {},
   "source": [
    "### Audio\n",
    "\n",
    "<img src='gif3.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text-to-speech\n",
    "- murf.ai\n",
    "- replica studios\n",
    "\n",
    "music composition\n",
    "- openAI jukedeck\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea01849",
   "metadata": {},
   "outputs": [],
   "source": [
    "What an AI engineer do exactly?\n",
    "\n",
    "How much python a lead should know?\n",
    "\n",
    "How much statistics a lead should know?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf3400",
   "metadata": {},
   "source": [
    "## 4. NLP Fundamentals and How to Build a Text Pre-processing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84540303",
   "metadata": {},
   "source": [
    "<img src='n4.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP\n",
    "\n",
    "- bridge the gap between human and machine\n",
    "\n",
    "2 types\n",
    "- NLU(Natural Language Understanding) - semantic analytics(context and intent)\n",
    "- NLG(Natural Language Generation) - generating next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc270035",
   "metadata": {},
   "outputs": [],
   "source": [
    "context \n",
    "\"your t-shirt is killer\"\n",
    "\n",
    "intent\n",
    "\"my mom gave me money to buy 1kg tomatos othersiwe she will be angry\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7cd2ab",
   "metadata": {},
   "source": [
    "### Text processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ca506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"A\" = 65   # ASCII, utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "you cannot feed the model with internet data directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d32810",
   "metadata": {},
   "outputs": [],
   "source": [
    "India != INDIA  # the data is not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw text\n",
    "\n",
    "\"<SUBJECT LINE> Employees details. \\\n",
    "<END><BODY TEXT>Attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove encodings\n",
    "\n",
    "\"Employees details. Attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower casing\n",
    "\n",
    "\"employees details. attached are 2 files 1st, one is pairoll 2nd is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits to words\n",
    "\n",
    "\"employees details. attached are two files first, one is pairoll second is healtcare !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters - @!#$%^\n",
    "\n",
    "\"employees details attached are two files first one is pairoll second is healtcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd23adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling corrections\n",
    "\n",
    "\"employees details attached are two files first one is payroll second is healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "\n",
    "\"employees details attached two files first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "\n",
    "\"employe detail attached two file first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization - ran->run, jumped->jump\n",
    "\n",
    "\"employe detail attach two file first one payroll second healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b161ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now the text is ready to feed into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16fe48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb89fa1",
   "metadata": {},
   "source": [
    "## 5. Text Normalization and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29c274",
   "metadata": {},
   "source": [
    "Tokenization Example - https://platform.openai.com/tokenizer\n",
    "\n",
    "<img src='v42.png' />\n",
    "\n",
    "<img src='v43.jpg' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ec2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this is an apple\n",
    "\n",
    "4 token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6553a",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "1. Word Tokenization\n",
    "2. Sentence Tokenization\n",
    "3. Regular Expression Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25801b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'this is a single sentence.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(tokens) # ['this', 'is', 'a', 'single', 'sentence', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9f8cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'single', 'sentence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation = [word.lower() for word in tokens if word.isalpha()]\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d421090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is the first sentence.', 'this is the second sentence.', 'this is the document.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57ce1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'sentence', '.'], ['this', 'is', 'the', 'second', 'sentence', '.'], ['this', 'is', 'the', 'document', '.']]\n"
     ]
    }
   ],
   "source": [
    "print([word_tokenize(sentence) for sentence in sent_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c195f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "print(stop_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c73f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'sentence', '.', 'second', 'sentence', '.', 'document', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "tokens = [token for token in word_tokenize(text) if token not in stop_words]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7067999",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT3\n",
    "\n",
    "500 Billion words\n",
    "\n",
    "175 billion parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c14fc",
   "metadata": {},
   "source": [
    "Tokens vs parameters\n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/tokens-vs-parameters-in-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ab0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9601b69",
   "metadata": {},
   "source": [
    "## 6. Embedding and Word2Vec\n",
    "\n",
    "Dataset - https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d65d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2df71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path):\n",
    "    file = open(path, 'r', encoding='utf8')\n",
    "    model = {}\n",
    "    \n",
    "    for l in file:\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        value = np.array([float(val) for val in line[1:]])\n",
    "        model[word] = value\n",
    "    \n",
    "    return model\n",
    "\n",
    "glove = loadGlove('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50a49c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python']   # vector embedding for the word Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "700b9c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92803 ,  0.29096 ,  0.67837 ,  1.0444  , -0.72551 ,  2.1995  ,\n",
       "        0.88767 , -0.94782 ,  0.67426 ,  0.24908 ,  0.95722 ,  0.18122 ,\n",
       "        0.064263,  0.64323 , -1.6301  ,  0.94972 , -0.7367  ,  0.17345 ,\n",
       "        0.67638 ,  0.10026 , -0.033782, -0.76971 ,  0.40519 , -0.099516,\n",
       "        0.79654 ,  0.1103  , -0.076053, -0.090434,  0.015021, -1.137   ,\n",
       "        1.6803  , -0.34424 ,  0.77538 , -1.8718  , -0.17148 ,  0.31956 ,\n",
       "        0.093062,  0.004996,  0.25716 ,  0.52207 , -0.52548 , -0.93144 ,\n",
       "       -1.0553  ,  1.4401  ,  0.30807 , -0.84872 ,  1.9986  ,  0.10788 ,\n",
       "       -0.23633 , -0.17978 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['neural']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0129d31",
   "metadata": {},
   "source": [
    "### How the system know that these words are similar?\n",
    "\n",
    "\n",
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf288386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "178263a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92180053]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['dog'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f968f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19825255]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['piano'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76946819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7839043]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['king'].reshape(1,-1), glove['queen'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb82b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf9f09d1",
   "metadata": {},
   "source": [
    "## Words in 2D Embedding Space\n",
    "\n",
    "<img src='v44.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "himanshu is taking the session. he will guide others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "place-delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER\n",
    "- names\n",
    "- places\n",
    "- organization\n",
    "- quantities\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7ee0f",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "Neurons to GenerativeAI - https://god-level-python.notion.site/Neurons-to-GenerativeAI-Live-Bootcamp-a59ec2f641084c488179271fc077f0c4?pvs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd64e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c527cb",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Research Paper\n",
    "- Attention is All You Need: https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd38eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda44121",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Large Language Models(How ChatGPT works?)\n",
    "2. State-of-the-art LLMs\n",
    "3. How difficult it is to build LLMs?\n",
    "4. What to know for LLMs on Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention is all you need - 2017 - Transformer\n",
    "\n",
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer-> Neural Network Architecture\n",
    "\n",
    "GPT\n",
    "\n",
    "Generative\n",
    "- statistical modeling\n",
    "    - generative modeling - predicting next number\n",
    "\n",
    "Pre-Trained\n",
    "- model that is trained on fundamental tasks\n",
    "\n",
    "Transformers\n",
    "- big computer that reduces the gap between a human and machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161aa509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friend\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67888949",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT-3\n",
    "\n",
    "5 datasets from internet\n",
    "\n",
    "500 billion tokens (words)\n",
    "\n",
    "175 billion parameters (memory of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bb3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837a3e5a",
   "metadata": {},
   "source": [
    "# Large Language Models(How ChatGPT works?)\n",
    "\n",
    "<img src='l1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50336bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue have the highest probability of being the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "the LLMs are just fancy autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ff8dd",
   "metadata": {},
   "source": [
    "### Attention and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt - the more clearly you define what you want from a LLM, you will get better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "- LLMs dont automatically improve with use\n",
    "- it will always start fresh in different sessions(new chat)\n",
    "- to get better output, you must adapt to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"take a deep breath and give me the roadmap for ML\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab817f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention\n",
    "\n",
    "Himanshu is in the market. He is going to bring fruits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910ba72",
   "metadata": {},
   "source": [
    "### the next word\n",
    "\n",
    "<img src='l2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the capital of germany?\n",
    "\n",
    "The capital of ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3397aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "the distribution is not deterministic\n",
    "\n",
    "same prompt - different distribution\n",
    "\n",
    "- the randomness is what we call generative in GenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the capital of Germany?\n",
    "\n",
    "Response: The capital of germany is Berlin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c5330",
   "metadata": {},
   "source": [
    "### Most Important part in ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the capital of france?\n",
    "what is the capital of germany?\n",
    "\n",
    "reponse: what is the capital of italy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53518",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI came up with an instruction manual\n",
    "\n",
    "- they took a small dataset of questions and answers\n",
    "- used it to fine-tune their base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ca9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction manual\n",
    "- it is not just autocomplete but it follows instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18600ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT does not really know anything\n",
    "\n",
    "- no self-awareness\n",
    "- no consciousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21133d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02743ca8",
   "metadata": {},
   "source": [
    "# State-of-the-art LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT-4 - OpenAI\n",
    "- it is not a single model\n",
    "- it is a combination of 8 models(each model with 220 billion parameters)\n",
    "\n",
    "LLaMa - MetaAI\n",
    "- it requires less computational power\n",
    "- available in different size\n",
    "\n",
    "PaLM - Google\n",
    "- 540 billion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d789c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8879d6da",
   "metadata": {},
   "source": [
    "## How difficult it is to build LLMs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - amount of data\n",
    "2 - computational resources\n",
    "3 - risk of bias\n",
    "4 - model robustness\n",
    "5 - interpretability and debugging\n",
    "6 - environment impact - carbon emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "when to buy vs when to build a LLM for your organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dff511",
   "metadata": {},
   "source": [
    "<img src='l3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ed4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406dfe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b87f8229",
   "metadata": {},
   "source": [
    "## Services to know for LLMs on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7712b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS\n",
    "\n",
    "- Experiment LLMs\n",
    "    - SageMaker - ML Workflow\n",
    "    - AWS Deep Learning Containers and DL AMIs(Amazon Machine Images)\n",
    "    - Pretrained models and SageMaker JumpStart\n",
    "\n",
    "- Deployment and productionizing LLMs\n",
    "    - SageMaker Endpoints\n",
    "    - Elastic Inference and Amazon EC2 Inf1 Instance\n",
    "    - AWS Lambda and Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecae763",
   "metadata": {},
   "outputs": [],
   "source": [
    "Azure\n",
    "\n",
    "- Experiment LLMs\n",
    "    - Azure OpenAI service\n",
    "    - Azure ML\n",
    "    - Azure Congnitive Services\n",
    "\n",
    "- Deployment and productionizing LLMs\n",
    "    - Azure Container Instances\n",
    "    - Azure Kubernetes Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1698be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP\n",
    "\n",
    "- Experiment LLMs\n",
    "    - VertexAI prediction\n",
    "    - IDE\n",
    "    - AI and ML Libraries\n",
    "\n",
    "- Deployment and productionizing LLMs\n",
    "    - VertexAI Prediction\n",
    "    - Google Kubernetes Engine (GKE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda44121",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- What exactly is GPT?\n",
    "    - Generative\n",
    "    - Pre-Trained\n",
    "    - Transformer\n",
    "\n",
    "- How does LLM generate a response and is different every time?\n",
    "- What are LLM parameters?\n",
    "- Does GPT get better over time?\n",
    "- How Does ChatGPT Work?\n",
    "- What is a Prompt? Why it matters?\n",
    "- Attention Mechanism\n",
    "- ChatGPT works forward, not backward\n",
    "- How does ChatGPT generate human-like responses?\n",
    "- Why do I get different responses every time I ask the same query?\n",
    "- Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01063c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "2017 - Attention is all you need - Transformers\n",
    "\n",
    "https://arxiv.org/abs/1706.03762\n",
    "\n",
    "BERT - first LLM by google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5391cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN\n",
    "RNN\n",
    "LSTM\n",
    "GRU\n",
    "\n",
    "Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c56da",
   "metadata": {},
   "source": [
    "## What exactly is GPT?\n",
    "\n",
    "<img src='l3.jpeg' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT - OpenAI\n",
    "\n",
    "\n",
    "Generative\n",
    "- statistical modeling\n",
    "    - generative modeling - predicting next number based on previous numbers or probabilities\n",
    "\n",
    "\n",
    "Pre-Trained\n",
    "- model that is trained on fundamental tasks\n",
    "\n",
    "GPT-3 is trained on 5 internet datasets - 500 billion words(tokens)\n",
    "\n",
    "\n",
    "Transformers\n",
    "- neural network architecture\n",
    "- big computer that reduces the gap between a human and a machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "- assembly language\n",
    "- algol\n",
    "- C\n",
    "- C++\n",
    "- python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a82525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friend\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Friend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6bd553",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "<img src='l5.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Himanshu is taking your working. He is going to answer your questions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b7ae4",
   "metadata": {},
   "source": [
    "## How does LLM generate a response and is different from google search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "google search is semantic search\n",
    "- search based on keywords, context and intent\n",
    "\n",
    "context\n",
    "\"your t-shirt is killer\"\n",
    "\n",
    "intent\n",
    "\"my mom gave me money to by potatos and if i dont bring it home she will be angry\"\n",
    "\n",
    "give you response which are available in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb83b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM give you response on which it is trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bb3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4dd479",
   "metadata": {},
   "source": [
    "## What are LLM parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680dada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '[!@#$%^&*]' - regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT-3 is trained on 500 billion tokens\n",
    "\n",
    "token\n",
    "- word token\n",
    "- sentence token\n",
    "- regular expression tokens\n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/tokens-vs-parameters-in-llms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3af54",
   "metadata": {},
   "source": [
    "tiktoken: https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "175 billion parameters (memory of the model)\n",
    "- weights and biases\n",
    "- patterns in the english words\n",
    "- relationship between words\n",
    "- how important a word is\n",
    "- grammer of creating a sentence in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "apple = 2\n",
    "absent = 3\n",
    ".\n",
    ".\n",
    ".\n",
    "z = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5346b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed0a2b",
   "metadata": {},
   "source": [
    "## Does GPT get better over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO\n",
    "\n",
    "500 billion tokens\n",
    "\n",
    "175 billion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG - connecting to other new data sources without training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837a3e5a",
   "metadata": {},
   "source": [
    "## Large Language Models(How ChatGPT works?)\n",
    "\n",
    "<img src='l1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"blue\" has the highest probability of being the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "the LLMs are just fancy autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ff8dd",
   "metadata": {},
   "source": [
    "## What is a Prompt? Why it matters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "the more clearly you define what you want from an LLM, you will get better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "- LLMs dont automatically improve with use\n",
    "- it will always start fresh in different sessions(new chat)\n",
    "- to get better output, you must adapt to the LLM (prompt engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec001a",
   "metadata": {},
   "source": [
    "## Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aab4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Himanshu is taking your working. He is going to answer your questions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "- transformers can keep this attention information for long text\n",
    "- transformers can process words together(parallel computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910ba72",
   "metadata": {},
   "source": [
    "## ChatGPT works forward, not backward\n",
    "\n",
    "<img src='l2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "what is the capital of germany?\n",
    "\n",
    "the capital of germany is ........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6daa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "the distribution is not deterministic\n",
    "\n",
    "same prompt => different distribution\n",
    "\n",
    "the randomness is what we call generative in GenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe6b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f27df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c67c5330",
   "metadata": {},
   "source": [
    "## How does ChatGPT generate human-like responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the capital of India?\n",
    "What is the capital of China?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060493f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response:\n",
    "    \n",
    "What is the capital of India?\n",
    "What is the capital of China?\n",
    "What is the capital of SriLanka?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI came up with a trick called Instruction Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "they fine-tune the GPT-3 on a dataset that is an Instruction manual\n",
    "\n",
    "\n",
    "- how humans give response\n",
    "- questions and answers response\n",
    "- they took a small dataset of questions and answers\n",
    "- used it to fine-tune their base model\n",
    "\n",
    "\n",
    "- it is not just autocomplete but it follows instructions\n",
    "\n",
    "\n",
    "ChatGPT does not really know anything\n",
    "\n",
    "- no self-awareness\n",
    "- no consciousness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bae498",
   "metadata": {},
   "source": [
    "## Why do I get different responses every time I ask the same query?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068936e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non deterministic probability distribution\n",
    "- it means more than 1 possible outcome\n",
    "- it used probability mehtods to generate response- the technique is called sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d789c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a410a88",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "How Does ChatGPT Work? [Detailed Analysis & Insights]\n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/how-does-chatgpt-work-detailed-analysis-insights\n",
    "\n",
    "\n",
    "Live Course: https://live.himanshuramchandani.co/\n",
    "\n",
    "\n",
    "Code: https://github.com/hemansnation/Generative-AI-Zero-to-Hero\n",
    "\n",
    "\n",
    "HuggingFace: https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f410d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

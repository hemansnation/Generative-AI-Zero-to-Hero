{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b156770",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### Module 2 - Neurons to GenerativeAI Architectures\n",
    "\n",
    "1. CNN RNN LSTM Encoder-Decoder\n",
    "2. Transformers\n",
    "3. Large Language Models\n",
    "4. Various LLMs in the Market\n",
    "5. Hugging Face Models [Hands-On]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3033b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97d00f1",
   "metadata": {},
   "source": [
    "# 1. CNN RNN LSTM Encoder-Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e605ac",
   "metadata": {},
   "source": [
    "# Neuron\n",
    "\n",
    "<img src='n11.jpeg' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ceb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "305ddaee",
   "metadata": {},
   "source": [
    "## Single Neuron (unit)\n",
    "\n",
    "with single input\n",
    "\n",
    "<img src='n3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0135d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Wx + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ed5f2",
   "metadata": {},
   "source": [
    "## multiple input\n",
    "\n",
    "<img src='n4.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x0w0 + x1w1 + x2w2 + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48e876d3",
   "metadata": {},
   "source": [
    "## Neural Network Equation\n",
    "\n",
    "<img src='nn2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "15412 -> activation function/transfer function -> 0 - 1 \n",
    "\n",
    "0 - 0.5 - not buying a car\n",
    "0.5 - 1 - buying a car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Wx + b\n",
    "\n",
    "y = mx + c => big number\n",
    "\n",
    "f(big number) = shrink the value in a small scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7563c",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "Sigmoid Activation\n",
    "\n",
    "<img src='nn3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "it is used for a neuron to make decision based on a range\n",
    "0 to 1, -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1446b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb932d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 types of activation function\n",
    "- linear\n",
    "- non linear\n",
    "    - sigmoid\n",
    "    - tanh\n",
    "    - relu\n",
    "    - leaky relu\n",
    "    - softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcd222",
   "metadata": {},
   "source": [
    "### sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "range -> (0,1)\n",
    "\n",
    "- predict the probability as an output\n",
    "- binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 2.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67deeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67baf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b49858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(155513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0fbed2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ee127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.598687660112452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d724a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias - additional parameter in the neuron that will help the \n",
    "        activation function to be shifted left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23420cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[12,-15,7] - tanh - [0.7, -0.2, 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd9f10",
   "metadata": {},
   "source": [
    "### What is the biggest real life example of linear algebra (vectors and matrix)?\n",
    "\n",
    "your screen\n",
    "\n",
    "1080px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6787d",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "https://github.com/hemansnation/AI-ML-MLOps-GenAI-Live-Summer-Cohort-2024/blob/main/Module%2007%20-%20NLP%20x%20Deep%20Learning/31_32_Convolutional%20Neural%20Networks.ipynb\n",
    "\n",
    "Convolution\n",
    "\n",
    "<img src='c1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3506cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN\n",
    "\n",
    "1000x1000x3 = huge number\n",
    "\n",
    "\n",
    "RGB\n",
    "0-255\n",
    "\n",
    "\n",
    "- convolution is a mathematical operation\n",
    "- the fundamental part of CNN is a filter(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6caf82",
   "metadata": {},
   "source": [
    "<img src='c2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d148e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47bc1f79",
   "metadata": {},
   "source": [
    "<img src='c5.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5edba01f",
   "metadata": {},
   "source": [
    "<img src='c6.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f9386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1883815",
   "metadata": {},
   "source": [
    "<img src='c14.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03af12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adbb8edb",
   "metadata": {},
   "source": [
    "<img src='c16.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e622da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## real world applications\n",
    "\n",
    "- facial recognition -> DCNN (Deep CNN)\n",
    "- image classification\n",
    "- object detection\n",
    "- medical image analysis - Xrays, MRIs\n",
    "- video analytics - action recognition\n",
    "- NLP - text classification, language translation, sentiment analysis(SpaCy, NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2418a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eeb210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c206c041",
   "metadata": {},
   "source": [
    "# Sequence Transduction\n",
    "\n",
    "<img src='t1.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "it is developed to solve a problem called sequence transduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb0f85",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "<img src='t2.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "the problem of long term dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416cb02",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)\n",
    "\n",
    "<img src='t3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeping important information and leave irrelavant information for a long period of time\n",
    "\n",
    "3 problems of LSTM and RNNs\n",
    "\n",
    "- sequential computation cause parallelization\n",
    "- long and short range dependencies\n",
    "- distance is linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN architectures\n",
    "- Bidirectional RNN\n",
    "- Gated Recurrent Unit (GRU)\n",
    "- Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c659162",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "\n",
    "<img src='t4.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8145cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paying attention to specific words\n",
    "\n",
    "\n",
    "\"Inverters is a great band. They play very good music.\"\n",
    "\n",
    "\"Himanshu is taking the session. He will explain in depth.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba078ca",
   "metadata": {},
   "source": [
    "<img src='t5.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1cc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18cc2858",
   "metadata": {},
   "source": [
    "<img src='t6.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699f35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a53e7bf5",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "<img src='t7.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a624ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "it works in parallel\n",
    "- each word on the input can be processed at the same time\n",
    "and does not depends on the previous word\n",
    "\n",
    "\n",
    "CNN and attention\n",
    "\n",
    "the problem of dependencies will not be solved with it\n",
    "\n",
    "thats why they came up with transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a9fb0",
   "metadata": {},
   "source": [
    "# 2. Transformer\n",
    "\n",
    "Research paper: https://arxiv.org/abs/1706.03762\n",
    "\n",
    "https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.XIWlzBNKjOR\n",
    "\n",
    "<img src='t8.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "the key innovation in transformers is self-attention\n",
    "\n",
    "\n",
    "RNNs and LSTM -> the model process the input is sequential\n",
    "\n",
    "\n",
    "transformer = encoder + decoder\n",
    "\n",
    "encoder and decoders = several identical layers\n",
    "\n",
    "\n",
    "\n",
    "encoder ->\n",
    "\n",
    "each layer = 2 sub-layers\n",
    "\n",
    "2 sub-layers = a self-attention mechanism + a position wise fully connected feedforward network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecbdefe",
   "metadata": {},
   "source": [
    "<img src='t9.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder\n",
    "\n",
    "2 sub-layers = a self-attention layer + cross attention layer + a position wise fully connected feedforward network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150d4b2",
   "metadata": {},
   "source": [
    "<img src='t10.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c8c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d75b9511",
   "metadata": {},
   "source": [
    "# Self-Attention\n",
    "\n",
    "<img src='t11.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9456e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "self-attention/scaled dot-product attention\n",
    "\n",
    "- calculates the relevance of each word in the sequence to the current word that being processed\n",
    "\n",
    "each input of the self attention is split into 3 transformations\n",
    "- query\n",
    "- key\n",
    "- value\n",
    "\n",
    "\n",
    "attention score\n",
    "\n",
    "softmax activation function - it normalize the attention scores within a sum to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positional Encoding\n",
    "\n",
    "the position of the word in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef1308",
   "metadata": {},
   "source": [
    "<img src='t12.png' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "the apple fruit is red in color. It is good for health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is self attention\n",
    "\n",
    "- assigning weigts to different parts of the sentence just to focus on the importance\n",
    "- scores based on the content of each position in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b98d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a7db1b",
   "metadata": {},
   "source": [
    "# 3. Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT\n",
    "\n",
    "Generative \n",
    "- statistical modeling \n",
    "    - generative modeling - use probability to predict next number\n",
    "\n",
    "Pre-Trained\n",
    "    - we train the model on fundamental concepts\n",
    "    \n",
    "Transformers\n",
    "    - neural network architecture that works on \n",
    "        attention mechanism to solve long term dependecy problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723edd7f",
   "metadata": {},
   "source": [
    "GPT3\n",
    "\n",
    "5 datasets from internet\n",
    "\n",
    "500+ billion tokens (words)\n",
    "\n",
    "175+ billion parameters (memory)\n",
    "\n",
    "\n",
    "Token and Parameters \n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/tokens-vs-parameters-in-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs are just fancy autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2c282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837a3e5a",
   "metadata": {},
   "source": [
    "# Large Language Models\n",
    "\n",
    "<img src='llm1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa8853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c32c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62585ca8",
   "metadata": {},
   "source": [
    "# 4. Various LLMs in the Market\n",
    "\n",
    "\n",
    "https://github.com/Hannibal046/Awesome-LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4 - OpenAI\n",
    "\n",
    "it is not a single model\n",
    "it is a combination of 8 models (each of 220 billion parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLaMa - MetaAI\n",
    "\n",
    "- it requires less computational power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PaLM - Google\n",
    "\n",
    "Pathways LM\n",
    "\n",
    "540 billion parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624890a7",
   "metadata": {},
   "source": [
    "# 5. Hugging Face Models [Hands-On]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d249a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tokenizers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd916c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging face will give you 2 main libraries\n",
    "\n",
    "- transformers - text data\n",
    "- diffusers - image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6018d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\himan\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a65e6d2034cacbcb0e85f3fc4bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\himan\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee4da0a114410885e757ed1f564ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ec965f665c48558603bf3f8228107e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e018d4b19b47d98a8ebbff6e844d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9996176958084106}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analysis = pipeline(\n",
    "\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "input_text = [\n",
    "\"Itâ€™s a great app, my biggest problem is the card readers regularly do not connect. Which is very poor customer service for us because we have to manually enter our customers debit cards, which takes time. This slows down our efficiency.\"\n",
    "]\n",
    "\n",
    "result = sentiment_analysis(input_text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718524de",
   "metadata": {},
   "source": [
    "## Microsoft DialoGPT-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0683629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62651ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbacd47984214c27a96fdc2ab5246b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\himan\\.cache\\huggingface\\hub\\models--microsoft--DialoGPT-medium. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2acae496f574806b2ccbcdb63429548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffd19a4095f4189923e82eef4d921ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cae546362e24d4db9ca29ca168d9e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df22c6630ba429d98fef8b9361a2246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\anaconda3\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157416e2723d4092984834a9f883d861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = \"microsoft/DialoGPT-medium\"\n",
    "max_length = 1000\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a8308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_hf = \"If dinosaurs were alive today, would they possess a threat to people?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a009b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: If dinosaurs were alive today, would they possess a threat to people?\n",
      "\n",
      "microsoft/DialoGPT-medium's Response: \n",
      "I think they would be more afraid of the humans.\n"
     ]
    }
   ],
   "source": [
    "user_input_ids = tokenizer.encode(user_prompt_hf + tokenizer.eos_token, return_tensors='pt')\n",
    "response_hf_encoded = model.generate(user_input_ids,\n",
    "                             max_length=max_length,\n",
    "                             pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "response_hf = tokenizer.decode(response_hf_encoded[:, user_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\n\\nPrompt: {user_prompt_hf}\\n\\n{hf_model}'s Response: \\n{response_hf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d215b5",
   "metadata": {},
   "source": [
    "### Questions answering web application with flask\n",
    "\n",
    "https://medium.com/@anoopjohny2000/building-a-question-answering-web-application-with-flask-and-transformers-9af2f69ef33d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198296e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039199d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e63338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
